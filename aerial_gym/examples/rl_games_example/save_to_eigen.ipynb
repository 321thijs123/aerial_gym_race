{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, path):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_dim, 256)\n",
    "        self.hidden_fc1 = nn.Linear(256, 128)\n",
    "        self.hidden_fc2 = nn.Linear(128, 64)\n",
    "        self.output_fc = nn.Linear(64, output_dim)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"0\", self.input_fc),\n",
    "                    (\"elu1\", nn.ELU()),\n",
    "                    (\"2\", self.hidden_fc1),\n",
    "                    (\"elu2\", nn.ELU()),\n",
    "                    (\"4\", self.hidden_fc2),\n",
    "                    (\"elu3\", nn.ELU()),\n",
    "                    (\"mu\", self.output_fc),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.load_network(path)\n",
    "\n",
    "    def load_network(self, path):\n",
    "        sd = torch.load(path)[\"model\"]\n",
    "\n",
    "        # clean the state dict and load it\n",
    "        od2 = OrderedDict()\n",
    "        for key in sd:\n",
    "            key2 = str(key).replace(\"a2c_network.actor_mlp.\", \"\")\n",
    "            key2 = key2.replace(\"a2c_network.\", \"\")\n",
    "            if \"a2c_network\" in key2 or \"value\" in key2 or \"sigma\" in key2:\n",
    "                continue\n",
    "            else:\n",
    "                print(key2)\n",
    "                od2[key2] = sd[str(key)]\n",
    "        # strictly load the state dict\n",
    "        self.network.load_state_dict(od2, strict=True)\n",
    "        print(\"Loaded MLP network from {}\".format(path))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "2.weight\n",
      "2.bias\n",
      "4.weight\n",
      "4.bias\n",
      "mu.weight\n",
      "mu.bias\n",
      "Loaded MLP network from networks/acc_command_2_multiplier_disturbance.pth\n",
      "tensor([[-1.8438e-04,  5.0467e-01,  9.3230e-02, -2.9466e-02]])\n",
      "input_fc.weight\n",
      "input_fc.bias\n",
      "hidden_fc1.weight\n",
      "hidden_fc1.bias\n",
      "hidden_fc2.weight\n",
      "hidden_fc2.bias\n",
      "output_fc.weight\n",
      "output_fc.bias\n",
      "(17, 256)\n",
      "[[-0.01250207  0.01663112  0.00866423 ...  0.00435116  0.08009952\n",
      "  -0.21129264]\n",
      " [ 0.7748038   0.07587783 -0.05085535 ... -0.13258356 -0.00889337\n",
      "   0.02463424]\n",
      " [-0.6327174   0.13020372  0.11861307 ...  0.01845818 -0.19888823\n",
      "   0.01966745]\n",
      " ...\n",
      " [ 0.17717712 -0.0470652  -0.0296856  ...  0.15510847  0.11242943\n",
      "  -0.20741701]\n",
      " [ 0.01679958  0.07810975 -0.08683077 ...  0.06576692 -0.02230075\n",
      "   0.01167393]\n",
      " [ 0.06269515 -0.35107088  0.05043096 ...  0.14248988 -0.03144643\n",
      "   0.07666203]]\n",
      "(256, 128)\n",
      "[[-0.25908226  0.02336972 -0.4415029  ... -0.3273674  -0.14353918\n",
      "   0.25987777]\n",
      " [-0.23861471  0.15876147  0.06278118 ...  0.19135207  0.01001304\n",
      "   0.05064647]\n",
      " [ 0.04655883  0.16842256  0.11997868 ...  0.25637132 -0.09318605\n",
      "   0.00484433]\n",
      " ...\n",
      " [ 0.4380467  -0.02884474  0.21292827 ... -0.25577193  0.06022721\n",
      "  -0.11884347]\n",
      " [-0.19638115 -0.13534659 -0.17541611 ... -0.08613922 -0.07895817\n",
      "  -0.10286161]\n",
      " [ 0.8219045   0.04729512  1.4032398  ...  0.3040539   0.18153611\n",
      "  -0.4099713 ]]\n",
      "(128, 64)\n",
      "[[ 0.1531608  -0.09233233  0.06334054 ... -0.07349533 -0.21070194\n",
      "   0.16278417]\n",
      " [ 0.05454547 -0.35784933  0.28219157 ... -0.35531312  0.1390601\n",
      "  -0.19432619]\n",
      " [ 0.00277527  0.04557116 -0.1726007  ... -0.15495291 -0.18502602\n",
      "   0.0052416 ]\n",
      " ...\n",
      " [ 0.0654783   0.14184898  0.18462558 ...  0.2596797  -0.00501325\n",
      "   0.05576542]\n",
      " [ 0.24278882 -0.12780045  0.03574796 ...  0.20826894 -0.20715185\n",
      "  -0.0641245 ]\n",
      " [-0.11907618 -0.30400378  0.16432005 ...  0.02096488  0.22358046\n",
      "  -0.4091484 ]]\n",
      "(64, 4)\n",
      "[[ 0.02094983  0.00746841  0.07987428 -0.02855426]\n",
      " [ 0.02982546  0.01048139 -0.00281204  0.02077114]\n",
      " [-0.05937747 -0.00396547  0.06308861  0.02389042]\n",
      " [ 0.00240972 -0.00671411 -0.00963343 -0.00184853]\n",
      " [ 0.01490256  0.09881873  0.00703401  0.04093287]\n",
      " [ 0.01415786  0.03395323 -0.08027223  0.00650948]\n",
      " [-0.04576857 -0.03265053 -0.03391093 -0.00167613]\n",
      " [-0.08447564 -0.04760617  0.0276629  -0.11955498]\n",
      " [ 0.02804711  0.05418843 -0.0253803  -0.01070857]\n",
      " [-0.01241575 -0.00179371  0.01930827 -0.00504513]\n",
      " [-0.00732464 -0.00578028 -0.00838709 -0.00314476]\n",
      " [ 0.04304128 -0.02145357  0.01223653  0.01658462]\n",
      " [ 0.01452204 -0.03656779  0.00834372 -0.01396697]\n",
      " [-0.05785952  0.04273952 -0.01580849  0.01885027]\n",
      " [ 0.03352937 -0.02406143  0.00349936  0.01138991]\n",
      " [-0.0067481  -0.02437064  0.01675535 -0.01525586]\n",
      " [-0.08832406 -0.03308038 -0.03419333  0.02191638]\n",
      " [ 0.00552559  0.01643719  0.01274749 -0.0552233 ]\n",
      " [-0.03412221  0.03504349  0.05250582  0.05787173]\n",
      " [-0.00798796 -0.0532647   0.01531788 -0.03689031]\n",
      " [-0.00622122 -0.01077888 -0.00166346  0.00772211]\n",
      " [-0.03182188  0.05233397  0.00626986  0.02553505]\n",
      " [ 0.00861937 -0.03112243 -0.02442499  0.03885609]\n",
      " [ 0.00944906  0.00438378  0.00537428  0.01583301]\n",
      " [-0.03676915 -0.02672751 -0.03656764  0.12290483]\n",
      " [ 0.01870148  0.0918937  -0.00986434 -0.06703653]\n",
      " [ 0.04110685 -0.07422044  0.06247237 -0.00395664]\n",
      " [-0.02170484 -0.01315504 -0.04263123  0.02130669]\n",
      " [-0.0083879   0.00834631  0.00893147  0.00668355]\n",
      " [-0.04607482  0.04264915 -0.02842139  0.01929598]\n",
      " [-0.04687461  0.07896978  0.02396367  0.10366918]\n",
      " [-0.04323311 -0.01582749  0.02539482 -0.04472316]\n",
      " [ 0.0004332   0.01325266  0.00126017 -0.03449753]\n",
      " [ 0.04234684 -0.04281468  0.01331081  0.06859425]\n",
      " [ 0.05927643  0.08274666  0.00714757  0.00181251]\n",
      " [ 0.06627981  0.02595563 -0.07372156 -0.04094679]\n",
      " [-0.02505361  0.0429031  -0.02338911 -0.02056564]\n",
      " [-0.0078129   0.01111992 -0.00045224  0.00669904]\n",
      " [ 0.06001219 -0.01332377 -0.03129205 -0.00223382]\n",
      " [-0.01877286 -0.03600854  0.00969651  0.0539117 ]\n",
      " [-0.0124324   0.00275992 -0.00430239  0.02321043]\n",
      " [ 0.0153369  -0.01540315  0.0143173  -0.0118591 ]\n",
      " [ 0.04706823 -0.0279637   0.01327306  0.03186468]\n",
      " [ 0.02776673  0.02901956  0.05942667 -0.01122638]\n",
      " [-0.0300846  -0.01687975 -0.03586511  0.02397284]\n",
      " [-0.03308837  0.01934265  0.00910964  0.02221979]\n",
      " [ 0.01921098  0.03447561 -0.00892512  0.03218145]\n",
      " [-0.01662066 -0.00209756  0.02201247  0.04659103]\n",
      " [ 0.04887619 -0.0463609   0.03688672  0.00076905]\n",
      " [ 0.01332507 -0.01563341  0.00113575 -0.02478995]\n",
      " [ 0.00828199  0.00070768 -0.0065045   0.02667769]\n",
      " [ 0.00346009 -0.03936108 -0.02432766 -0.01675502]\n",
      " [-0.04225501 -0.02038139 -0.01152507 -0.00230325]\n",
      " [ 0.0083077  -0.02666424  0.01101704  0.00729471]\n",
      " [ 0.01036786  0.00138709 -0.03809313  0.03063937]\n",
      " [ 0.03845864 -0.11160342 -0.0014655  -0.0890264 ]\n",
      " [ 0.01642293  0.039335    0.01997299 -0.02508617]\n",
      " [ 0.04204396 -0.03931678  0.06328736 -0.02582074]\n",
      " [ 0.00794962  0.04256298  0.01526832 -0.01167363]\n",
      " [ 0.01773394  0.01870742 -0.00542899 -0.01152244]\n",
      " [ 0.00434584  0.00137701 -0.00778081 -0.00988723]\n",
      " [-0.05478159  0.05531781 -0.01631141 -0.03164576]\n",
      " [ 0.07046955  0.05186307 -0.01434075  0.01417039]\n",
      " [-0.04359553 -0.05805595  0.01780151  0.0057541 ]]\n",
      "(256,)\n",
      "(128,)\n",
      "(64,)\n",
      "(4,)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "filepath = \"networks/acc_command_2_multiplier_disturbance.pth\"\n",
    "\n",
    "\n",
    "# load model into MLP network\n",
    "\n",
    "model = MLP(17, 4, filepath)\n",
    "\n",
    "zero_input = torch.zeros(1, 17)\n",
    "with torch.no_grad():\n",
    "    output = model(zero_input)\n",
    "    print(output)\n",
    "\n",
    "# # have the model as a set of numpy arrays that can be multiplied to one another\n",
    "\n",
    "def get_model_weights(model):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name)\n",
    "        if \"weight\" in name:\n",
    "            weights.append(param.data.numpy().T)\n",
    "        elif \"bias\" in name:\n",
    "            biases.append(param.data.numpy())\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "weights, biases = get_model_weights(model)\n",
    "\n",
    "# # make numpy array for each weight and bias and save them to a file as a text file that can be read by c++\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    with open(f\"networks/weight_{i}.txt\", \"w\") as file:\n",
    "        file.write(f\"{w.shape[0]}\\n{w.shape[1]}\\n\")\n",
    "        print(w.shape)\n",
    "        print(w)#, w.flatten())\n",
    "        w = w.flatten()\n",
    "        for item in w:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "for i, b in enumerate(biases):\n",
    "    with open(f\"networks/bias_{i}.txt\", \"w\") as file:\n",
    "        # write shape in dim 0\n",
    "        file.write(f\"{b.shape[0]}\\n\")\n",
    "        print(b.shape)\n",
    "        b = b.flatten()\n",
    "        for item in b:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
